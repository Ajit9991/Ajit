{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_12980746.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajit9991/Ajit/blob/master/A1_12980746.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCymodx2TyC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyMW7j9DUbEI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "File available at <https://github.com/Ajit9991/ML2019_12980746>\n",
        "\n",
        "UNIVERSITY OF TECHNOLOGY SYDNEY\n",
        "\n",
        "Machine Learning- Assignment 1\n",
        "\n",
        "Student Name – Ajit Pokharkar\n",
        "\n",
        "Student ID – 12980746\n",
        "\n",
        "TITLE – Approximate Nearest Neighbours\n",
        "\n",
        "INTRODUCTION\n",
        "\n",
        "The preferred paper is walk through the a Approximate Nearest Neighbours, which is an essential part of machine learning. The nearest neighbour problem is the following: Given a set of n points P = (PI, . . . ,p,} in some metric space X, pre-process P so as to efficiently answer queries which require finding the point in P closest to a query point q E X( (Indyk, 1999). They have discovered the different approaches to achieve the results for query time over the data set and they do provide the applications to retrieve the information, pattern recognition etc. The authors have provided enough theorems and examples to make his point valid.\n",
        "\n",
        "\n",
        "CONTENT \n",
        "\n",
        "The paper has elaborated four major sections a very well. Firstly, the introduction section has a definition of nearest neighbour search (NNS)problem. Furthermore, the author has explained the method to achieve the result of the problem. The introduction section has three subsection motivation, previous work and overview of results and techniques respectively. The motivation segment discourse the importance of the nearest neighbour problem to resolve the issue of similarity objects in a different application. Also, have elaborated the exact cause of this problem and have defined a technique to reduce the cause. The second segment of the introduction part is previous work, in which the authors have studied several existing research paper and talk about the paper and their techniques and the outcome of the technique. The technique talk about the exponential query time, and improvement of the brute force algorithm for time-bound. The third segment, an overview of the result, defined the actual result of this paper with three proposition and address the problem of point location in equal balls. This segment mentioned about the akin method to store the equal balls in a dictionary with the format of the constrained cells. Mainly, in this segment, the author has discovered various new techniques to gain results.\n",
        "\n",
        "The second major section of this paper is preliminaries, in this section author have provided the definition and the fact to point the location of the ball. This section mentioned the notation for space, norm, vector, and hamming metric space of dimension to define the radius of the ball.\n",
        "The third section belongs to the drop to point location in equal Balls (PLEB), this section defines the way to minimize the problems of point location in equal balls by reducing the NNS. In this section, there is a reduction comparison of NNS to PLEB with pre-processing and query time. The section mentioned the ring-cover tree, this help to find ring separator or a cover at any point. Moreover, the paper has provided the definition for ring separator, cluster and cover, and theorem to make his point. The paper shows the construction procedure and analysis for Ring-cover Trees. The paper shows an efficient way to examine a ring-cover tree.\n",
        "\n",
        "The fourth section discovers the techniques to solve the point location in equal ball problem. The first technique is Elias Bucketing algorithm help to store the ball in a dictionary in the format of the bounded cell with an akin method, this help to achieve the query time. The hash function to store the information of ball in the hash table. The second technique is, Locality-Sensitive Hashing, this method uses the family hash function to implement a static dictionary. It also shows, how dot product is useful to solve the point set problem. The third technique is a randomized indexing method, which is useful to perform insertion and deletion by indexing. In the bucket method, insertion and deletion of elements get it done in the hash table.\n",
        "\n",
        "Lastly, the paper has mentioned the dimension reduction technique. The combination of this technique with proposition 2, they have achieved the result of given proposition 3. To find the isometric embedding they have provided the different theorem, facts and definition. The main purpose of this paper is pre-processing the data and store data in order to achieve the query time.\n",
        "\n",
        "\n",
        "INNOVATION\n",
        "\n",
        "Machine learning uses the Approximate Nearest Neighbours theory every now and then for various application. The purpose of this theory is to find the point in the provided dataset, which closes to the query point. The Approximate Nearest Neighbours includes the various approaches like kd-trees, Locality Sensitive Hashing and brute force search to solve the problem. The approximate nearest neighbours have different applications for information retrieval, pattern recognition and fast clustering. However, this paper has published in 1999. The author has focused on the curse dimensionality issue, which was discovered by Papert and Minsky in 1960. This paper has a unique technique and novelty.\n",
        "\n",
        "The structure of the paper is well designed, as it discusses the different theory from the various research paper and explained the method very appropriately. The author has used pre-processing cost polynomial and query-time polynomial algorithms to progress the known bounds. Moreover, the author has described, how they have used distance metric to identify the resemblance of objects.\n",
        "\n",
        "To improve the information retrieval performance, the author has used random projection with classical geometric lemma and provide an experimental result which they have published in the  1997s paper. The author has used the ring-cover tree technique to minimize the problem data structure creation in pre-processing. While solving the problem of NNS, the author has introduced the new problem of point location in equal balls(PLEB). The author has provided the solutions of two different technique which make this paper novel. The first technique is Elias Bucketing algorithm with an akin method and they introduce the second technique called Locality-Sensitive hashing. They have used a hash function to avoid the collision of the high possibility of the objects those near to each other. Furthermore, they have proved the fast NNS algorithm with pre-processing cost, work effectively in linear and sub-linear. The cluster web document uses the hamming space and resemblance measure to maintain point distance in the manner and to identify the pattern (Broder, 1997).  The paper gives the fast clustering and locality sensitive algorithm to solve the dynamic closest pair problem. The provided algorithm have their own advantage and simple to implement for different applications.\n",
        "\n",
        "\n",
        "TECHNICAL QUALITY\n",
        "\n",
        "In this paper, the quality of technical theorem is very well presented. Firstly, they have mentioned about the curse dimensionality problem and the origin of this problem. The two major factors to achieve the result of this problem is pre-processing cost and query time. The result of the first algorithm shows the improvement in query performance over the real-time datasets (Gionis, 1997). This paper has given the importance of NNS problem to a different application by providing various examples, which clears the concept of NNS. The latent semantic indexing technique help to reduce the dimension to retrieve the text document information (Berry, January 1995). \n",
        "\n",
        "The author has explained the procedure of PLEB in a very simple manner. It is helpful to find a very quick result, of the closest pair. It tells how bucket and randomized methods make simpler to check for the radius which has two diverse points. The PLEB has made easy to look at the bio-chromatic and multi-chromatic problem within the time-bound. The dynamic closest problem has a various application like greedy matching, hierarchical agglomerative  clustering and the given data structure have O(n) distance computations per update(Eppstein, 1998). Thus, this paper provides a new way to achieve fairly accurate answer in sub- linear time.\n",
        "\n",
        "\n",
        "APPLICATION AND X-FACTOR\n",
        "\n",
        "In the motivation segment, the author have provided various examples which are having the dimensionality in thousands and how other technique merely help to reduce the few dimensions, for example, latent semantic indexing. This paper discussed the curse of dimensionality, how it affects the machine learning as well as several other application. The author has tried to solve this problem by using approximate nearest neighbour search with the different methods and technique and have proposed their own solutions to this problem. Before their proposed solution, they have studied related work of this problem and have mentioned about it in the paper. I would like to say, this is a good application to achieve the proposed technique. Furthermore, this research help to various applications like data mining, database, video & image database, text pattern recognition etc. In their study, they found that the first time nearest neighbour proposed in query time O(2^d log n) and pre-processing cost O(n^2^d+1) by Lipton and Dobkin. Later On, the various scientist tried to achieve the best result for pre-processing time and query time but everyone’s result vary in the notation for ANN.\n",
        "\n",
        "The author has compared their results with Frankl and Maehara (Frankl, 1988), and discover their improvement for constants as they are very important for time bounds exponent of the algorithm. The author has provided a fair comparison of NNS and ANN. In addition, the interesting part of this paper is, the combination of technology to implement the theorem is very effective.\n",
        "\n",
        "PRESENTATION\n",
        "\n",
        "The presentation of the paper was excellent. The paper has explained all the features in detail, which make this paper very good. I would like to address the features of the presentation paper as follow:\n",
        "1.\tContent style\n",
        "\n",
        "Initially, author talk about the nearest neighbour problem and explained the various paper results for this problem. The author has mentioned the different application where this problem helped to solve the problem. This paper has given the comparison of a different algorithm for pre-processing cost and query time for algorithm results and proposed the best solution.\n",
        "\n",
        "2.\tTechnical explanation\n",
        "\n",
        "The author has provided a very innovative explanation for technical theorem, definition and proposition. This paper has provided various examples to understand the theorem and definition. This paper gives the logic to every section and the author have proved the theorem very accurately. The author has illustrated such a complex theory in a simple way that was outstanding.\n",
        "\n",
        "3.\tPaper Format\n",
        "\n",
        "The referencing and formatting of this paper is very standard. The author has studied various other research paper to pull out the information and provide the proper referencing to it. \n",
        "\n",
        "\n",
        "Reference\n",
        "\n",
        "Berry, D. &. (January 1995). 'A Case Study of Latent Semantic Indexing'. U.T Knoxville Technical report.\n",
        "\n",
        "Broder, A. &. (1997). 'Syntactic clustering of the web'. In: Proceedings of The Sixth International World Wide Web Conference , 391-404.\n",
        "\n",
        "Eppstein, D. (1998). 'Fast hierarchical clustering and other application of dynamic closest pairs'. In: Proceedings of the Ninth ACM -SIAM Symposium on Discrete Algorithm.\n",
        "\n",
        "Frankl, P. &. (1988). The Johnson-Lindenstrauss Lemma and the Sphericity of Some Graphs. Journal Of Combinatorial Theory, Series B 44, 355-362.\n",
        "\n",
        "Gionis, A. I. (1997). 'Similarity Search in High Dimensions via Hashing'. 518-529.\n",
        "\n",
        "Indyk, P. &. (1999). 'approximate nearest neighbors towards removing the curse of dimensionality'. 1-20.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}